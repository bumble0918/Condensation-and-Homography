{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part H: Tracking and Homographies - Zuohe Zheng\n",
    "\n",
    "In this part we use Practical 9c to track the positions of the four corners of the square and project a cube into the images. \n",
    "\n",
    "TO DO: QUESTIONS TO THINK ABOUT...\n",
    "\n",
    "- Do the results look realistic? \n",
    "- If not then what factors do you think might be causing this\n",
    "\n",
    "\n",
    "TO DO: your routines for computing a homography and extracting a valid rotation and translation go in the code below. Tips:\n",
    "- you may define functions for T and H matrices respectively.\n",
    "- you may need to turn the points into homogeneous form before any other computation. \n",
    "- you may need to solve a linear system in Ah = 0 form. Write your own routines or using the builtin function 'svd'. \n",
    "- you may apply the direct linear transform (DLT) algorithm to recover the best homography H.\n",
    "- you may explain what & why you did in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import io\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import os # for reading all files in a folder\n",
    "pylab.rcParams['figure.figsize'] = (12.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of running the code here, you can also save the output of each function in a numpy array in HW2_Practical9c \n",
    "# and load it here. This could be handy if you need different hyperparameters for each corner.\n",
    "\n",
    "# LLs = HW2_Practical9c( 'll' )\n",
    "# LRs = HW2_Practical9c( 'lr' )\n",
    "# ULs = HW2_Practical9c( 'ul' )\n",
    "# URs = HW2_Practical9c( 'ur' )\n",
    "\n",
    "LLs=np.load(\"r_ll.npy\")\n",
    "LRs=np.load(\"r_lr.npy\")\n",
    "ULs=np.load(\"r_ul.npy\")\n",
    "URs=np.load(\"r_ur.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The goal of this function is to project points in XCart through projective camera\n",
    "#defined by intrinsic matrix K and extrinsic matrix T.\n",
    "def projectiveCamera(K,T,XCart):\n",
    "    \n",
    "    # TO DO: Replace this\n",
    "    # XImCart =\n",
    "\n",
    "    # TO DO: Convert Cartesian 3d points XCart to homogeneous coordinates XHom\n",
    "    # by appending a row of 1 to the original point coordinates to form [u,v,w,1]\n",
    "    XHom = np.concatenate((XCart, np.ones((1,XCart.shape[1]))), axis=0)\n",
    "    # TO DO: Apply extrinsic matrix to XHom, to move to frame of reference of camera\n",
    "    # = lambda * [x',y',1, 1/lambda]\n",
    "    xCamHom1 = T @ XHom\n",
    "    # TO DO: Project points into normalized camera coordinates xCamHom (remove 4th row)\n",
    "    # = lambda * [x',y',1]\n",
    "    xCamHom = xCamHom1[0:3,:]\n",
    "    # TO DO: Move points to image coordinates xImHom by applying intrinsic matrix\n",
    "    # = lambda * [x,y,1]\n",
    "    xImHom = K @ xCamHom\n",
    "    # TO DO: Convert points back to Cartesian coordinates xImCart\n",
    "    # x = (lambda * x) / lambda\n",
    "    # y = (lambda * y) / lambda\n",
    "    XImCart = xImHom[0:2,:] / np.tile([xImHom[2,:]],(2,1))\n",
    "    return XImCart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveAXEqualsZero(A):\n",
    "    # TO DO: Write this routine - it should solve Ah = 0   \n",
    "    h = np.zeros(shape = [np.size(A),1])\n",
    "    [U,L,Vt] = np.linalg.svd(A)\n",
    "    V = np.transpose(Vt)\n",
    "    h = V[:,-1]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal of function is to estimate pose of plane relative to camera (extrinsic matrix)\n",
    "# given points in image xImCart, points in world XCart and intrinsic matrix K\n",
    "\n",
    "def estimatePlanePose(XImCart,XCart,K):\n",
    "\n",
    "    # TO DO: replace this\n",
    "    #T = \n",
    "\n",
    "    # TO DO: Convert Cartesian image points XImCart to homogeneous representation XImHom\n",
    "    # by appending a row of 1 to the original point coordinates to form [x,y,1]\n",
    "    XImHom = np.concatenate((XImCart, np.ones((1,XImCart.shape[1]))), axis=0)\n",
    "    \n",
    "    # TO DO: Convert image co-ordinates XImHom to normalized camera coordinates XCamHom    \n",
    "    # multiply with inverse of intrinsic matrix\n",
    "    XCamHom = np.linalg.inv(K) @ XImHom\n",
    "    \n",
    "    # TO DO: Estimate homography H mapping homogeneous (x,y) coordinates of positions\n",
    "    # in real world to XCamHom (convert XCamHom to Cartesian, calculate the homography) -\n",
    "    # use the routine you wrote for Practical 1B\n",
    "    \n",
    "    # Extract the u and v coordinates of Cartesian 3d points XCart\n",
    "    XCart = XCart[0:2,:]\n",
    "    \n",
    "    # Convert XCart to homogeneous coordinates XCartHom\n",
    "    # [u,v] to [u,v,1]\n",
    "    XCartHom = np.concatenate((XCart, np.ones((1,XCart.shape[1]))), axis=0)\n",
    "    \n",
    "    # Then construct the matrix A, size (n_points,9) \n",
    "    n_points = np.shape(XCamHom)[1]\n",
    "    A = np.zeros(shape = [n_points*2,9])\n",
    "    for n in range(n_points):\n",
    "        A[2*n,[0,1,2]] = 0\n",
    "        A[2*n,[3,4,5]] = -XCartHom[:,n]\n",
    "        A[2*n,[6,7,8]] = XCartHom[:,n] * XCamHom[1,n]\n",
    "        A[2*n+1,[0,1,2]] = XCartHom[:,n]\n",
    "        A[2*n+1,[3,4,5]] = 0\n",
    "        A[2*n+1,[6,7,8]] = -XCartHom[:,n] * XCamHom[0,n]\n",
    "    \n",
    "    # Solve Ah = 0\n",
    "    h = solveAXEqualsZero(A)\n",
    "    # Reshape h into the matrix H, values of h go first into rows of H\n",
    "    h_width = np.sqrt(np.size(h))\n",
    "    h_width = int(h_width)\n",
    "    H = np.reshape(h,[h_width,h_width])\n",
    "     \n",
    "    # TO DO: Estimate first two columns of rotation matrix R from the first two\n",
    "    # columns of H using the SVD\n",
    "    # SVD decomposition of the first two columns of H\n",
    "    [U,L,Vt] = np.linalg.svd(H[:,0:2])\n",
    "    R = np.zeros(shape=[h_width,h_width])\n",
    "    # Replace L with [1,0;0,1;0,0] to form the first two columns of R\n",
    "    l = np.array([[1,0],[0,1],[0,0]])\n",
    "    R[:,0:2] = U @ l @ Vt\n",
    "\n",
    "    # TO DO: Estimate the third column of the rotation matrix by taking the cross\n",
    "    # product of the first two columns\n",
    "    R[:,2] = np.cross(R[:,0],R[:,1])\n",
    "        \n",
    "    # TO DO: Check that the determinant of the rotation matrix is positive - if\n",
    "    # not then multiply last column by -1.\n",
    "    if np.linalg.det(R) <= 0 :\n",
    "        R[:,-1] = - R[:,-1]\n",
    "    \n",
    "    # TO DO: Estimate the translation t by finding the appropriate scaling factor k\n",
    "    # and applying it to the third colulmn of H\n",
    "    # Find translation scaling factor between old and new values\n",
    "    Lamb = H / R\n",
    "    lamb = np.sum(Lamb[0:3,0:2]) / 6\n",
    "    t = H[:,-1] / lamb\n",
    "    \n",
    "    # TO DO: Check whether t_z is negative - if it is then multiply t by -1 and\n",
    "    # the first two columns of R by -1.\n",
    "    if t[-1] < 0 :\n",
    "        t = -t\n",
    "        R[:,0:2] = -R[:,0:2]\n",
    "    \n",
    "            \n",
    "    # TO DO: Assemble transformation into matrix form\n",
    "    # append [Tx,Ty,Tz] to R as the last column\n",
    "    # then append [0,0,0,1] as the last row to form the final transformation matrix\n",
    "    t = np.reshape(t,[3,1])\n",
    "    T = np.concatenate((R, t), axis=1)\n",
    "    T = np.concatenate((T, np.array([[0,0,0,1]])), axis=0)\n",
    "    \n",
    "    return T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images in folder\n",
    "images = []\n",
    "nFrame = 0\n",
    "folder = 'Pattern01/'\n",
    "for frameNum in sorted(os.listdir(folder)):\n",
    "    images.append(cv.imread(folder+frameNum))\n",
    "    nFrame += 1\n",
    "# # plot first image \n",
    "# plt.imshow(images[0])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Coordinates of the known target object (a dark square on a plane) in 3D:\n",
    "XCart = np.array([[-50, -50,  50,  50],\n",
    "          [50, -50, -50,  50],\n",
    "            [0, 0, 0, 0]])\n",
    "\n",
    "# These are some approximate intrinsics for this footage.\n",
    "K = np.array([[640, 0, 320],\n",
    "          [0, 512, 256],\n",
    "            [0, 0, 1]])\n",
    "\n",
    "# Define 3D points of wireframe object.\n",
    "XWireFrameCart = np.array([[-50, -50,  50,  50, -50, -50,  50,  50],\n",
    "          [50, -50, -50,  50, 50, -50, -50,  50],\n",
    "            [0, 0, 0, 0, -100, -100, -100, -100, ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "for iFrame in range(nFrame):\n",
    "    print('Processing Frame', iFrame)\n",
    "    xImCart = np.array([LLs[iFrame,:].T, ULs[iFrame,:].T, URs[iFrame,:].T, LRs[iFrame,:].T]).T\n",
    "\n",
    "    # get a frame from footage \n",
    "    im = images[iFrame]\n",
    "\n",
    "    # Draw image and 2d points\n",
    "    plt.imshow(im)\n",
    "    plt.scatter(x = xImCart[0,:], y = xImCart[1,:],c = 'r')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    #TO DO: Use your routine to calculate TEst the extrinsic matrix relating the\n",
    "    #plane position to the camera position.\n",
    "    #T = estimatePlanePose(xImCart, XCart, K);\n",
    "    TEst = estimatePlanePose(xImCart,XCart,K)\n",
    "    \n",
    "    # TO DO: Draw a wire frame cube using data XWireFrameCart. You need to\n",
    "    # 1) project the vertices of a 3D cube through the projective camera;\n",
    "    # 2) draw lines betweeen the resulting 2d image points.\n",
    "    # Note: CONDUCT YOUR CODE FOR DRAWING XWireFrameCart HERE\n",
    "    \n",
    "    XWireFrameCartProjected = projectiveCamera(K,TEst,XWireFrameCart)\n",
    "    plt.plot(XWireFrameCartProjected[0,],XWireFrameCartProjected[1,],'g.')\n",
    "\n",
    "    # Connect the points to draw the frame of the cube\n",
    "    for cPoint in range(4):\n",
    "        plt.plot([XWireFrameCartProjected[0,cPoint],XWireFrameCartProjected[0,cPoint+4]], \\\n",
    "                 [XWireFrameCartProjected[1,cPoint],XWireFrameCartProjected[1,cPoint+4]],'g-') \n",
    "    for cPoint in range(3):\n",
    "        plt.plot([XWireFrameCartProjected[0,cPoint],XWireFrameCartProjected[0,cPoint+1]], \\\n",
    "                 [XWireFrameCartProjected[1,cPoint],XWireFrameCartProjected[1,cPoint+1]],'g-') \n",
    "        plt.plot([XWireFrameCartProjected[0,cPoint+4],XWireFrameCartProjected[0,cPoint+5]], \\\n",
    "                 [XWireFrameCartProjected[1,cPoint+4],XWireFrameCartProjected[1,cPoint+5]],'g-')\n",
    "    plt.plot([XWireFrameCartProjected[0,0],XWireFrameCartProjected[0,3]], \\\n",
    "                 [XWireFrameCartProjected[1,0],XWireFrameCartProjected[1,3]],'g-') \n",
    "    plt.plot([XWireFrameCartProjected[0,4],XWireFrameCartProjected[0,7]], \\\n",
    "                 [XWireFrameCartProjected[1,4],XWireFrameCartProjected[1,7]],'g-') \n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figures above show the result of four corners of the black square tracked using condensation algorithm and the wireframe cube biult based on the tracking points and homography estimation. The tracking results in all frames are correct and most of cubes built are realistic except for the homography transformation works bad in a few frames because of the characteristic of equation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, distribution region can be restricted to simplify and improve the tracking. For example, when tracking upper right corner, likelihood or particles can be simply restricted to only the upper right region of the current frame. An elegant way is to use edge detector, which is implemented in another file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic method to improve the tracking result is adjust particle number. A number around 3000 of particles can have a good tracking result. The lower number of particles may not cover the all image and is easy to cause error or missings, but using too many particles is redundant. Different numbers of particles were chosen for four corners. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to adjust the noise level with the moving velocity of camera. When the camera move fast, the objects in the scene have large displacements and the particles with small distribution range are hard to keep pace with the moving object. So lower noise std can be used when the image is still, to make particles concentrated, and higher noise std when camera moves fast. Calculating displacement before adding noise to new particles can be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the street scene used in task9B, the likelihood figures of matching black corners are obviously more clear and concentrated. The MAP estimation performance better when the template and the image are simple. Using other template match algorithms like non-local-means can also improve the tracking results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
